<!DOCTYPE html>

<html lang="pt-BR" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Acessando o Cluster &#8212; Documentação Cluster Cin latest</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/groundwork.css?v=594d7a89" />
    <script src="_static/documentation_options.js?v=3ccd3dfb"></script>
    <script src="_static/doctools.js?v=9bcbadda"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/translations.js?v=71a39b36"></script>
    <link rel="index" title="Índice" href="genindex.html" />
    <link rel="search" title="Buscar" href="search.html" />
    <link rel="next" title="O que é um cluster de computadores?" href="TheoryCluster/Theory_cluster.html" />
    <link rel="prev" title="Arquitetura do cluster Apuana" href="cluster_cin.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navegação</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="Índice Geral"
             accesskey="I">índice</a></li>
        <li class="right" >
          <a href="TheoryCluster/Theory_cluster.html" title="O que é um cluster de computadores?"
             accesskey="N">próximo</a> |</li>
        <li class="right" >
          <a href="cluster_cin.html" title="Arquitetura do cluster Apuana"
             accesskey="P">anterior</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Documentação Cluster Cin latest</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Acessando o Cluster</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="acessando-o-cluster">
<span id="h-js2b7t82mute"></span><h1>Acessando o Cluster<a class="headerlink" href="#acessando-o-cluster" title="Link para este cabeçalho">¶</a></h1>
<p>Para acessar o cluster é necessário ter um login cin.ufpe.br e ter o
acesso habilitado as máquinas de acesso do cluster, também é necessário
estar na VPN do CIn. O primeiro passo é solicitar o acesso ao cluster através do <a class="reference external" href="https://docs.google.com/forms/d/1bDDI9WIi1aipfp9BqoCOYne7CFQtOGjgdDzh9kr0drw/edit">formulário de cadastro</a>.</p>
</section>
<section id="acessando-a-vpn-do-cin">
<h1>Acessando a VPN do CIn<a class="headerlink" href="#acessando-a-vpn-do-cin" title="Link para este cabeçalho">¶</a></h1>
<p>Mesmo fazendo a conexão utilizando a rede interna do CIn, é necessário usar a VPN do CIn. Para maiores informações sobre o uso da VPN do CIn, consultar a documentação disponível na página do HelpDesk para VPN do CIn (<a class="reference external" href="https://helpdesk.cin.ufpe.br/redes/vpn">https://helpdesk.cin.ufpe.br/redes/vpn</a>). O canal para tirar dúvidas sobre conexão com a VPN é através do HelpDesk (<a class="reference external" href="mailto:helpdesk&#37;&#52;&#48;cin&#46;ufpe&#46;br">helpdesk<span>&#64;</span>cin<span>&#46;</span>ufpe<span>&#46;</span>br</a>)</p>
</section>
<section id="conectando-a-maquina-de-acesso">
<h1>Conectando a Maquina de Acesso<a class="headerlink" href="#conectando-a-maquina-de-acesso" title="Link para este cabeçalho">¶</a></h1>
<p>O envio de tarefas para o cluster precisa ser feito a partir de uma
maquina de acesso, a entrada na maquina de acesso é realizado através do
SSH</p>
<p>        ssh &lt;login&gt;&#64;slurm-client1.cin.ufpe.br</p>
<p>Uma vez conectado na máquina de acesso é possível alocar e editar seus
jobs a partir de comandos
<a class="reference external" href="https://www.google.com/url?q=https://slurm.schedmd.com/documentation.html&amp;sa=D&amp;source=editors&amp;ust=1683228690609179&amp;usg=AOvVaw2aSvDJwDiM7wf_WKq0h5lp">slurm</a>.
Primeiramente, você precisará preparar seu ambiente de trabalho no
servidor que você utilizará. Jobs que utilizam máquinas virtuais (Docker
e afins) não serão aprovados, pois abrem brechas de segurança. Qualquer
biblioteca que necessite de instalação, por favor, nos contate e faremos
a instalação o mais rápido possível. Para acessar o servidor que
realizará o processamento, utilize o comando “salloc”, como no exemplo
abaixo:</p>
<p>salloc</p>
<p>Nossos servidores já tem o gerenciador de pacotes
<a class="reference external" href="https://www.google.com/url?q=https://www.anaconda.com/products/distribution&amp;sa=D&amp;source=editors&amp;ust=1683228690610341&amp;usg=AOvVaw3cLVSQY5yUsKcLch94qn4r">conda</a> para
qualquer projeto que for realizado em Python. Os comandos de git também
estão disponíveis e prontos para uso. Após a preparação do seu ambiente,
volte para o nodo de login com o comando “exit” e rode o seu job com o
comando
<a class="reference external" href="https://www.google.com/url?q=https://slurm.schedmd.com/srun.html&amp;sa=D&amp;source=editors&amp;ust=1683228690610939&amp;usg=AOvVaw3QWOdTZiBB1V14-VrnC1a2">srun</a>.
Exemplo:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">srun --gpus=N_GPUS --cpus-per-task=N_CPUS nvidia-smi</span>
</pre></div>
</div>
</section>
<section id="ambientes-virtuais-python">
<span id="h-fnvohiub06p3"></span><h1>Ambientes Virtuais Python<a class="headerlink" href="#ambientes-virtuais-python" title="Link para este cabeçalho">¶</a></h1>
<p>Um ambiente virtual em Python é um ambiente local e isolado no qual você
pode instalar ou desinstalar pacotes Python sem interferir no ambiente
global (ou em outros ambientes virtuais). Geralmente reside em um
diretório. Para usar um ambiente virtual, você deve ativá-lo. Ativar um
ambiente essencialmente define variáveis ​​de ambiente em seu shell para
que:</p>
<ul class="simple">
<li><p>‘python’ aponta para a versão correta do Python para aquele ambiente</p></li>
<li><p>‘python’ procura pelos pacotes no ambiente virual</p></li>
<li><p>‘pip install’ instala pacotes no ambiente virtual</p></li>
<li><p>Qualquer comando shell instalado via ‘pip install’ é disponibilizado</p></li>
</ul>
</section>
<section id="pip-virtualenv">
<span id="h-t03rdi3pn51o"></span><h1>Pip/Virtualenv<a class="headerlink" href="#pip-virtualenv" title="Link para este cabeçalho">¶</a></h1>
<p>Pip é o gerenciador de pacotes preferido para Python e cada cluster
fornece várias versões do Python por meio do módulo associado que vem
com o pip. Para instalar novos pacotes, primeiro você terá que criar um
espaço pessoal para armazená-los. A solução preferida é usar ambientes
virtuais.</p>
<p>Primeiro, carregar o modulo Python que deseja utilizar</p>
<p> module load Python3.10</p>
<p>Modulos Disponiveis</p>
<ul class="simple">
<li><p>Python3.10 -&gt; Python/3.10.8</p></li>
<li><p>Python3.9 -&gt; Python/3.9.6</p></li>
<li><p>Python3.8 -&gt; Python/3.8.6</p></li>
</ul>
<p>Depois crie um ambiente virutal (onde &lt;env&gt; é o nome do ambiente) no seu
diretório home:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">python -m venv $HOME/&lt;env&gt;</span>
</pre></div>
</div>
<p>Para ativar o ambiente criado:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">source $HOME/&lt;env&gt;/bin/activate</span>
</pre></div>
</div>
<p>Você agora pode instalar qualquer pacote Python utilizando o comando
pip, exemplo pytorch:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install torch torchvision</span>
</pre></div>
</div>
<p>Recomendamos que para a criação do ambiente para rodar o seus job,
alocar uma maquina de forma interativa utilizando o comando salloc, nele
você pode criar e testar o ambiente, uma vez criado e funcional, para
utilizar você deve carregar o modulo e ativar o ambiente no seu script.</p>
</section>
<section id="execucao-de-jobs">
<span id="h-elx4sixwhp8c"></span><h1>Execução de jobs<a class="headerlink" href="#execucao-de-jobs" title="Link para este cabeçalho">¶</a></h1>
<p>Ao escrever um script .sh, é necessário ativar o ambiente no início e
instalar os pacotes necessários. Um exemplo de um script com tensorflow
é mostrado a seguir:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>!/bin/bash
<span class="gp">#</span>SBATCH<span class="w"> </span>--job-name<span class="o">=</span>test_job
<span class="gp">#</span>SBATCH<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--mem<span class="w"> </span>16G
<span class="gp">#</span>SBATCH<span class="w"> </span>-c<span class="w"> </span><span class="m">8</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>-o<span class="w"> </span>job.log
<span class="gp">#</span>SBATCH<span class="w"> </span>--output<span class="o">=</span>job_output.txt
<span class="gp">#</span>SBATCH<span class="w"> </span>--error<span class="o">=</span>job_error.txt

<span class="gp"># </span>carregar<span class="w"> </span>versão<span class="w"> </span>python
<span class="go">module load Python/3.10</span>
<span class="gp"># </span>ativar<span class="w"> </span>ambiente
<span class="go">source $HOME/env_teste/bin/activate</span>
<span class="gp"># </span>executar<span class="w"> </span>.py
<span class="go">python $HOME/test_dir/test.py</span>
</pre></div>
</div>
<section id="comandos-basicos-de-gerenciamento-de-jobs">
<span id="h-h11648s05oky"></span><h2>Comandos básicos de gerenciamento de jobs<a class="headerlink" href="#comandos-basicos-de-gerenciamento-de-jobs" title="Link para este cabeçalho">¶</a></h2>
<p>Para agendar o job faça:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">sbatch test_slurm.sh</span>
</pre></div>
</div>
<p>Para verificar erros no job faça (dentro do diretório do arquivo
job_error.txt):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cat job_error.txt</span>
</pre></div>
</div>
<p>Para observar os outputs do job faça (dentro do diretório do arquivo
job_output.txt):</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">cat job_output.txt</span>
</pre></div>
</div>
<p>Para verificar a posição do job na fila faça:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">squeue</span>
</pre></div>
</div>
<p>Para cancelar o job faça:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">scancel job_id</span>
</pre></div>
</div>
</section>
<section id="exemplo-com-repositorio-publico-do-github">
<span id="h-p9bbx0k61d7n"></span><span id="h-16ozdksheroh"></span><h2>Exemplo com repositório público do GitHub<a class="headerlink" href="#exemplo-com-repositorio-publico-do-github" title="Link para este cabeçalho">¶</a></h2>
<p>Primeiro é necessário clonar o repositório. Obs.: o diretório home do
usuário é sincronizado entre todas as máquinas.</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone https://github.com/username/repoName.git</span>
</pre></div>
</div>
<p>Depois de clonar o repositório, é criado um script .sh. Uma das
alternativas é utilizando nano:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">nano test_slurm.sh</span>
</pre></div>
</div>
<p>Em seguida, o usuário preenche o script com as diretivas do SBATCH que
ele acha necessário e depois com os comandos que devem ser executados no
node. Primeiro, será apresentado um script que faz uso de Pytorch.</p>
<p>test_slurm.sh</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>!/bin/bash
<span class="gp">#</span>SBATCH<span class="w"> </span>--job-name<span class="o">=</span>test_job
<span class="gp">#</span>SBATCH<span class="w"> </span>--ntasks<span class="o">=</span><span class="m">1</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--mem<span class="w"> </span>16G
<span class="gp">#</span>SBATCH<span class="w"> </span>-c<span class="w"> </span><span class="m">8</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>-o<span class="w"> </span>job.log
<span class="gp">#</span>SBATCH<span class="w"> </span>--output<span class="o">=</span>job_output.txt
<span class="gp">#</span>SBATCH<span class="w"> </span>--error<span class="o">=</span>job_error.txt

<span class="gp"># </span>carregar<span class="w"> </span>versão<span class="w"> </span>python
<span class="go">module load Python/3.9.6</span>
<span class="gp"># </span>criar<span class="w"> </span>ambiente
<span class="go">python -m venv $HOME/env_teste</span>
<span class="gp"># </span>ativar<span class="w"> </span>ambiente
<span class="go">source $HOME/env_teste/bin/activate</span>
<span class="gp"># </span>instalar<span class="w"> </span>pacotes<span class="w"> </span>desejados
<span class="go">pip install pytorch</span>
<span class="go">pip install pandas</span>
<span class="go">pip install matplotlib</span>
<span class="go">pip install seaborn</span>
<span class="go">Pip install IPython</span>
<span class="gp"># </span>executar<span class="w"> </span>.py
<span class="go">python $HOME/repoName/thisScript.py</span>
</pre></div>
</div>
<p>Perceba a criação de um novo ambiente e em seguida sua ativação. Aqui
foi realizado o dowgrade da versão do Python de 3.10 para 3.9. Isto foi
feito porque ainda existem bugs da classe DataLoader do PyTorch ao
utilizar o python 3.10. O cluster é bastante versátil neste aspecto,
pois pode-se escolher a versão do python (dentre as listadas acima) e
das dependências mais adequadas para o funcionamento do seu código no
ambiente virtual.</p>
</section>
<section id="exemplo-com-repositorio-privado-do-github">
<span id="h-u2s1lukw4mc7"></span><h2>Exemplo com repositório privado do GitHub<a class="headerlink" href="#exemplo-com-repositorio-privado-do-github" title="Link para este cabeçalho">¶</a></h2>
<p>Clonando um repositório privado :</p>
<p>Para clone repositorios privados recomendamos conectar na maquina de
login (slurm-client1) passando adiante o seu agente SSH, permitindo a
você utilizar a chave SSH configurada na sua maquina local na sessão
SSH, para tal é preciso utilizar o parametro -A</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">ssh -A &lt;login&gt;@slurm-client1.cin.ufpe.br</span>
</pre></div>
</div>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">git clone git@github.com:username:token@github.com/username/repoName.git</span>
</pre></div>
</div>
</section>
<section id="sincronizacao-de-arquivos-entre-o-cluster-a-sua-maquina">
<span id="h-kbo1jo3m9z40"></span><h2>Sincronização de Arquivos Entre o Cluster a Sua Máquina<a class="headerlink" href="#sincronizacao-de-arquivos-entre-o-cluster-a-sua-maquina" title="Link para este cabeçalho">¶</a></h2>
<p>Para a sincronização/transferência de arquivos entre sua máquina e o
cluster deve ser utilizado o comando rsync
(<a class="reference external" href="https://www.google.com/url?q=https://download.samba.org/pub/rsync/rsync.1&amp;sa=D&amp;source=editors&amp;ust=1683228690625949&amp;usg=AOvVaw1h4cJRq-mEcdnOojWx8lGE">Documentação</a>,
<a class="reference external" href="https://www.google.com/url?q=https://www.digitalocean.com/community/tutorials/how-to-use-rsync-to-sync-local-and-remote-directories-pt&amp;sa=D&amp;source=editors&amp;ust=1683228690626302&amp;usg=AOvVaw2x91BoV8AGqpGJzdYZulSa">Tutorial</a>)
através da diretório home da máquina de login, lembrando que este é
sincronizado com os nós de computação do cluster.</p>
<p>Exemplos:</p>
<ul class="simple">
<li><p>Sincronizando pasta da máquina local para o cluster:
rsync –bwlimit=1000 -azP pasta-1 &lt;login&gt;&#64;slurm-client1.cin.ufpe.br:~</p></li>
<li><p>A pasta de nome “pasta-1” vai ser copiada/sincronizada para a pasta
de nome “pasta-1” no seu diretório home “~/pasta-1”</p></li>
<li><p>O argumento –bwlimit limita a velocidade de transferência, dado em
KBytes por segund</p></li>
<li><p>O argumento -a é para archive mode, sendo equivalente a utilização
dos argumentos “ -rlptgoD “</p></li>
<li><p>O argumento -z realiza a compressão dos dados para transferência</p></li>
<li><p>O argumento -P mostra o progresso da transferência e resume
transferências interrompidas</p></li>
<li><p>Sincronizando pasta do cluster para máquina local:
rsync –bwlimit=1000 -azP &lt;login&gt;&#64;slurm-client1.cin.ufpe.br:~/pasta-1
~</p></li>
<li><p>Mesmo do exemplo anterior, porém a ordem é invertida, a pasta-1 do
diretório home do cluster é copiada para o diretório home local</p></li>
</ul>
<p>A utilização do rsync também é recomendada para transferências dentro da
própria máquina do cluster quando for realizada entre volumes em rede,
como por exemplo transferências do diretório home para o diretório /tmp
local do nó de computação</p>
</section>
</section>
<section id="particoes-e-limites-de-recursos">
<span id="h-6xrj2d7u8h14"></span><h1>Partições e limites de recursos<a class="headerlink" href="#particoes-e-limites-de-recursos" title="Link para este cabeçalho">¶</a></h1>
<section id="fairshare">
<h2>Fairshare<a class="headerlink" href="#fairshare" title="Link para este cabeçalho">¶</a></h2>
<p>No cluster Apuana o Fairshare está implementado de forma simples, onde o
cada orientador possui uma cota de recursos pré definida.
Esta cota é dividida igualmente entre seus orientandos ativos que
estão associados a ele. Ou seja, Se os outros orientandos do seu professor não
estiverem usando o cluster, sua “fatia” disponível de rescursos será maior.</p>
</section>
<section id="qos">
<h2>QoS<a class="headerlink" href="#qos" title="Link para este cabeçalho">¶</a></h2>
<p>No Slurm, uma Qualidade de Serviço (QoS) é uma configuração que atribui
limites de recursos específicos, como tempo máximo de CPU, tempo de espera e memória
para trabalhos e controla sua prioridade de despacho em um cluster.
Foram definidos 2 (dois) QoS principais para os usuários com as seguintes limitações:</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>QoS</p></td>
<td><p>Máx CPUs</p></td>
<td><p>Máx RAM</p></td>
<td><p>Máx GPUs</p></td>
</tr>
<tr class="row-even"><td><p>simple</p></td>
<td><p>16</p></td>
<td><p>64GB</p></td>
<td><p>2</p></td>
</tr>
<tr class="row-odd"><td><p>complex</p></td>
<td><p>48</p></td>
<td><p>500GB</p></td>
<td><p>4</p></td>
</tr>
</tbody>
</table>
</section>
<section id="particoes">
<h2>Partições<a class="headerlink" href="#particoes" title="Link para este cabeçalho">¶</a></h2>
<p>Anteriormente, o cluster continha duas partições: long e short. A partição
long era a partição padrão, adequada para processar cargas com poucos
recursos em longos períodos de tempo. Já a partição short era adequada
para processar cargas com mais recursos, porém, em um menor período de
tempo. Um resumo destas informações, juntamente com seus recursos, é apresentado na tabela abaixo.</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>Nome</p></td>
<td><p>Tempo máximo</p></td>
<td><p>Preempção</p></td>
<td><p>CPU</p></td>
<td><p>MEM</p></td>
<td><p>GPU</p></td>
<td><p>Prioridade</p></td>
</tr>
<tr class="row-even"><td><p>long</p></td>
<td><p>7 dias</p></td>
<td><p>A partir de 2 dias de execução</p></td>
<td><p>16</p></td>
<td><p>32</p></td>
<td><p>1</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-odd"><td><p>short</p></td>
<td><p>2 dias</p></td>
<td><p>A partir de 2 horas de execução</p></td>
<td><p>32</p></td>
<td><p>64</p></td>
<td><p>2</p></td>
<td><p>50</p></td>
</tr>
</tbody>
</table>
<p>O cluster foi atualizado e possui agora sete partições: <code class="docutils literal notranslate"><span class="pre">emergency</span></code>, <code class="docutils literal notranslate"><span class="pre">install</span></code>,
<code class="docutils literal notranslate"><span class="pre">debug</span></code>, <code class="docutils literal notranslate"><span class="pre">short-simple</span></code>, <code class="docutils literal notranslate"><span class="pre">short-complex</span></code>, <code class="docutils literal notranslate"><span class="pre">long-simple</span></code>, <code class="docutils literal notranslate"><span class="pre">long-complex</span></code>. Isso foi realizado
para deixar mais específico o propósito de cada job, e as únicas partições que
aceitam execução de forma interativa são as <code class="docutils literal notranslate"><span class="pre">install</span></code> e <code class="docutils literal notranslate"><span class="pre">debug</span></code>.</p>
<table class="docutils align-default">
<tbody>
<tr class="row-odd"><td><p>Partição</p></td>
<td><p>Interativa</p></td>
<td><p>Recursos</p></td>
<td><p>Máximo de tempo</p></td>
<td><p>Prioridade</p></td>
<td><p>Máximo de jobs</p></td>
</tr>
<tr class="row-even"><td><p>emergency</p></td>
<td><p>❌</p></td>
<td><p>Completo (override)</p></td>
<td><p>1 dia</p></td>
<td><p>1000</p></td>
<td><p>N/A</p></td>
</tr>
<tr class="row-odd"><td><p>install</p></td>
<td><p>✅</p></td>
<td><p>Meio node</p></td>
<td><p>30 mins</p></td>
<td><p>100</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-even"><td><p>debug</p></td>
<td><p>✅</p></td>
<td><p>Completo node</p></td>
<td><p>30 mins</p></td>
<td><p>10</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>short-simple</p></td>
<td><p>❌</p></td>
<td><p>Meio node</p></td>
<td><p>2 dias</p></td>
<td><p>100</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even"><td><p>short-complex</p></td>
<td><p>❌</p></td>
<td><p>Completo node</p></td>
<td><p>2 dias</p></td>
<td><p>50</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>long-simple</p></td>
<td><p>❌</p></td>
<td><p>Meio node</p></td>
<td><p>7 dias</p></td>
<td><p>50</p></td>
<td><p>4</p></td>
</tr>
<tr class="row-even"><td><p>long-complex</p></td>
<td><p>❌</p></td>
<td><p>Completo node</p></td>
<td><p>7 dias</p></td>
<td><p>25</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
</section>
<section id="atualizacao-de-scripts">
<h2>⚠️ Atualização de scripts!<a class="headerlink" href="#atualizacao-de-scripts" title="Link para este cabeçalho">¶</a></h2>
<p>Com as atualizações realizadas no cluster, o padrão dos scripts foi modificado.
O template padrão para execução de jobs via sbatch é:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="gp">#</span>!/bin/bash
<span class="gp">#</span>SBATCH<span class="w"> </span>--mem<span class="w"> </span>2G
<span class="gp">#</span>SBATCH<span class="w"> </span>-c<span class="w"> </span><span class="m">1</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>-p<span class="w"> </span>short-complex
<span class="gp">#</span>SBATCH<span class="w"> </span>--gpus<span class="o">=</span><span class="m">1</span>
<span class="gp">#</span>SBATCH<span class="w"> </span>--mail-type<span class="o">=</span>FAIL,END
<span class="gp">#</span>SBATCH<span class="w"> </span>--mail-user<span class="o">=</span>user@cin.ufpe.br

<span class="go">ENV_NAME=$1</span>
<span class="go">module load Python3.10 Xvfb freeglut glew</span>
<span class="go">python -m venv $HOME/doc/$ENV_NAME</span>
<span class="go">source $HOME/doc/$ENV_NAME/bin/activate</span>
<span class="go">which python</span>
<span class="go">pip install -r ../requirements.txt</span>
<span class="go">pip list</span>
</pre></div>
</div>
<p>Já para a partição interativa, pode ser utilizado o comando:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">salloc --mem 64G -c 48 --gpus 1</span>
</pre></div>
</div>
</section>
</section>
<section id="politicas-de-priorizacao-de-jobs">
<span id="h-r8jgqwv0re1s"></span><span id="h-isb7a7i9a70r"></span><h1>Políticas de priorização de jobs<a class="headerlink" href="#politicas-de-priorizacao-de-jobs" title="Link para este cabeçalho">¶</a></h1>
<p>Cada partição possui um fator de prioridade. A partição que pode ser utilizada
para submissão de job com maior prioridade é a <strong>``short-simple``</strong> (prioridade=100)
enquanto a que possui menor prioridade é a <strong>long-complex</strong> (prioridade=25).
Além disso, como a quantidade de recursos pode variar em cada job, considera-se
o fator <strong>JobSize</strong>. Este fator prioriza jobs que solicitam menos recursos computacionais.</p>
<p>Considere dois usuários que submetem jobs utilizando a partição ‘long-complex’.
O usuário A solicita X de CPU e o usuário B solicita 2X de CPU. O usuário A,
possui maior prioridade. Portanto, para cada job é calculado um fator de
prioridade  de acordo com a partição e recursos solicitados.
Este fator de prioridade varia de 0.0 a 1.0.</p>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/cin-logo.png" alt="Logo de Cluster Cin"/>
            </a></p>
  <div>
    <h3><a href="index.html">Tabela de Conteúdo</a></h3>
    <ul>
<li><a class="reference internal" href="#">Acessando o Cluster</a></li>
<li><a class="reference internal" href="#acessando-a-vpn-do-cin">Acessando a VPN do CIn</a></li>
<li><a class="reference internal" href="#conectando-a-maquina-de-acesso">Conectando a Maquina de Acesso</a></li>
<li><a class="reference internal" href="#ambientes-virtuais-python">Ambientes Virtuais Python</a></li>
<li><a class="reference internal" href="#pip-virtualenv">Pip/Virtualenv</a></li>
<li><a class="reference internal" href="#execucao-de-jobs">Execução de jobs</a><ul>
<li><a class="reference internal" href="#comandos-basicos-de-gerenciamento-de-jobs">Comandos básicos de gerenciamento de jobs</a></li>
<li><a class="reference internal" href="#exemplo-com-repositorio-publico-do-github">Exemplo com repositório público do GitHub</a></li>
<li><a class="reference internal" href="#exemplo-com-repositorio-privado-do-github">Exemplo com repositório privado do GitHub</a></li>
<li><a class="reference internal" href="#sincronizacao-de-arquivos-entre-o-cluster-a-sua-maquina">Sincronização de Arquivos Entre o Cluster a Sua Máquina</a></li>
</ul>
</li>
<li><a class="reference internal" href="#particoes-e-limites-de-recursos">Partições e limites de recursos</a><ul>
<li><a class="reference internal" href="#fairshare">Fairshare</a></li>
<li><a class="reference internal" href="#qos">QoS</a></li>
<li><a class="reference internal" href="#particoes">Partições</a></li>
<li><a class="reference internal" href="#atualizacao-de-scripts">⚠️ Atualização de scripts!</a></li>
</ul>
</li>
<li><a class="reference internal" href="#politicas-de-priorizacao-de-jobs">Políticas de priorização de jobs</a></li>
</ul>

  </div>
  <div>
    <h4>Tópico anterior</h4>
    <p class="topless"><a href="cluster_cin.html"
                          title="capítulo anterior">Arquitetura do cluster Apuana</a></p>
  </div>
  <div>
    <h4>Próximo tópico</h4>
    <p class="topless"><a href="TheoryCluster/Theory_cluster.html"
                          title="próximo capítulo">O que é um cluster de computadores?</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>Essa Página</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/usage.rst.txt"
            rel="nofollow">Exibir Fonte</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Busca rápida</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Ir" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navegação</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="Índice Geral"
             >índice</a></li>
        <li class="right" >
          <a href="TheoryCluster/Theory_cluster.html" title="O que é um cluster de computadores?"
             >próximo</a> |</li>
        <li class="right" >
          <a href="cluster_cin.html" title="Arquitetura do cluster Apuana"
             >anterior</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">Documentação Cluster Cin latest</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Acessando o Cluster</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2025.
      Criada usando <a href="https://www.sphinx-doc.org/pt_BR/master">Sphinx</a> 8.2.3.
    </div>
  </body>
</html>